{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/keras-team/keras-tuner.git\n",
    "!pip install autokeras\n",
    "from IPython.display import clear_output\n",
    "clear_output(wait=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, pickle\n",
    "import numpy as np\n",
    "import autokeras as ak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s28.dat\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s14.dat\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s01.dat\n",
      "first\n",
      "1\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s15.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s29.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s03.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s17.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s16.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s02.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s06.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s12.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s13.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s07.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s11.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s05.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s04.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s10.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s09.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s21.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s20.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s08.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s22.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s23.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s27.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s32.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s26.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s30.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s24.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s18.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s19.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s25.dat\n",
      "next\n",
      "./datasets/DEAP/deap-dataset/data_preprocessed_python/s31.dat\n",
      "next\n"
     ]
    }
   ],
   "source": [
    "path = \"./datasets/DEAP/deap-dataset/data_preprocessed_python/\"\n",
    "data = np.array([[]])\n",
    "labels = np.array([[]])\n",
    "test_data = np.array([[]])\n",
    "test_labels = np.array([[]])\n",
    "\n",
    "i = 0\n",
    "for files in os.listdir(path):\n",
    "    file = os.path.join(path, files)\n",
    "    \n",
    "    print(file)\n",
    "    with open(file, \"rb\") as f:\n",
    "        content = pickle.load(f, encoding=\"latin1\")\n",
    "        if i==0:\n",
    "            if file.endswith(\"s28.dat\") or file.endswith(\"s14.dat\"):\n",
    "                test_data = content['data']\n",
    "                test_labels = content['labels']\n",
    "                continue\n",
    "            print(\"first\")\n",
    "            labels = content['labels']\n",
    "            data = content['data']\n",
    "            i=i+1\n",
    "            print(i)\n",
    "            continue\n",
    "        print(\"next\")\n",
    "        if file.endswith(\"s28.dat\") or file.endswith(\"s14.dat\"):\n",
    "                test_data = np.concatenate((test_data, np.array(content['labels'])))\n",
    "                test_labels = np.concatenate((test_data, np.array(content['data'])))\n",
    "                continue\n",
    "        labels = np.concatenate((labels, np.array(content['labels'])))\n",
    "        data = np.concatenate((data, np.array(content['data'])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12902400"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content['data'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content['labels'].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 40, 8064)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 4)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 40, 8064)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 4)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "valence = labels[:,0]\n",
    "arousal = labels[:,1]\n",
    "dominance = labels[:,2]\n",
    "liking = labels[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_valence = test_labels[:,0]\n",
    "test_arousal = test_labels[:,1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, optimizers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import json\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Hyperparams -----------------\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "VALIDATION_SPLIT = 0.2  # from X_train used as val\n",
    "LEARNING_RATE = 1e-3\n",
    "PATIENCE_ES = 15\n",
    "PATIENCE_RLR = 5\n",
    "INPUT_TIMESTEPS = 40\n",
    "INPUT_FEATURES = 8064\n",
    "TARGET_DIM = 1\n",
    "# ----------------- Model builder -----------------\n",
    "def build_lstm_model(timesteps=INPUT_TIMESTEPS, features=INPUT_FEATURES, output_dim=TARGET_DIM):\n",
    "    inp = layers.Input(shape=(timesteps, features), name=\"eeg_input\")\n",
    "\n",
    "    # Optional small input projection to reduce dimensionality (improves speed)\n",
    "    x = layers.TimeDistributed(layers.Dense(128, activation=\"relu\"))(inp)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "\n",
    "    # Stacked LSTMs with return_sequences for intermediate layers\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.1)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(512, return_sequences=True, dropout=0.2, recurrent_dropout=0.1)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    \n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(256, return_sequences=True, dropout=0.2, recurrent_dropout=0.1)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.1)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Final LSTM returns last output (no return_sequences)\n",
    "    x = layers.Bidirectional(\n",
    "        layers.LSTM(64, return_sequences=False, dropout=0.2, recurrent_dropout=0.1)\n",
    "    )(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "\n",
    "    # Dense head\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.25)(x)\n",
    "\n",
    "    out = layers.Dense(output_dim, activation=\"linear\", name=\"fuzzy_out\")(x)\n",
    "\n",
    "    model = models.Model(inputs=inp, outputs=out, name=\"deep_bi_lstm_regressor\")\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- Reproducibility -----------------\n",
    "import random\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"deep_bi_lstm_regressor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"deep_bi_lstm_regressor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ eeg_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8064</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032,320</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">788,480</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_20                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">4,198,400</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)       │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_21                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">2,623,488</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_34          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_22                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │       <span style=\"color: #00af00; text-decoration-color: #00af00\">656,384</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_35          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)        │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_23                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fuzzy_out (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ eeg_input (\u001b[38;5;33mInputLayer\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m8064\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed_6              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,032,320\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_31          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_19 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_19                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │       \u001b[38;5;34m788,480\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_32          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_20                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │     \u001b[38;5;34m4,198,400\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_33          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1024\u001b[0m)       │         \u001b[38;5;34m4,096\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_21                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │     \u001b[38;5;34m2,623,488\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_34          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m512\u001b[0m)        │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_22                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │       \u001b[38;5;34m656,384\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_35          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m256\u001b[0m)        │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_23                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │       \u001b[38;5;34m164,352\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)                 │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_36          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_20 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_37          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_21 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ fuzzy_out (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,482,241</span> (36.17 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m9,482,241\u001b[0m (36.17 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,476,993</span> (36.15 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m9,476,993\u001b[0m (36.15 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,248</span> (20.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,248\u001b[0m (20.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\n",
      "Epoch 1: val_loss improved from None to 3.25362, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 41s - 1s/step - loss: 3.5649 - mae: 3.5649 - val_loss: 3.2536 - val_mae: 3.2536 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 2: val_loss improved from 3.25362 to 2.75674, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 29s - 958ms/step - loss: 3.2183 - mae: 3.2183 - val_loss: 2.7567 - val_mae: 2.7567 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 3: val_loss improved from 2.75674 to 2.41751, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 29s - 981ms/step - loss: 2.9718 - mae: 2.9718 - val_loss: 2.4175 - val_mae: 2.4175 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 4: val_loss improved from 2.41751 to 2.04878, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 37s - 1s/step - loss: 2.6140 - mae: 2.6140 - val_loss: 2.0488 - val_mae: 2.0488 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 5: val_loss improved from 2.04878 to 1.90193, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 36s - 1s/step - loss: 2.4961 - mae: 2.4961 - val_loss: 1.9019 - val_mae: 1.9019 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 6: val_loss improved from 1.90193 to 1.68398, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 37s - 1s/step - loss: 2.2517 - mae: 2.2517 - val_loss: 1.6840 - val_mae: 1.6840 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 7: val_loss improved from 1.68398 to 1.58867, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 38s - 1s/step - loss: 2.1786 - mae: 2.1786 - val_loss: 1.5887 - val_mae: 1.5887 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 8: val_loss did not improve from 1.58867\n",
      "30/30 - 39s - 1s/step - loss: 2.0106 - mae: 2.0106 - val_loss: 1.8155 - val_mae: 1.8155 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 9: val_loss did not improve from 1.58867\n",
      "30/30 - 40s - 1s/step - loss: 1.9415 - mae: 1.9415 - val_loss: 1.9384 - val_mae: 1.9384 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 10: val_loss did not improve from 1.58867\n",
      "30/30 - 39s - 1s/step - loss: 1.9780 - mae: 1.9780 - val_loss: 1.8237 - val_mae: 1.8237 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 11: val_loss did not improve from 1.58867\n",
      "30/30 - 40s - 1s/step - loss: 1.9529 - mae: 1.9529 - val_loss: 1.8711 - val_mae: 1.8711 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 12: val_loss did not improve from 1.58867\n",
      "\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "30/30 - 40s - 1s/step - loss: 1.8796 - mae: 1.8796 - val_loss: 1.9319 - val_mae: 1.9319 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 13: val_loss did not improve from 1.58867\n",
      "30/30 - 40s - 1s/step - loss: 1.8582 - mae: 1.8582 - val_loss: 1.6681 - val_mae: 1.6681 - learning_rate: 5.0000e-04\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 14: val_loss did not improve from 1.58867\n",
      "30/30 - 41s - 1s/step - loss: 1.8240 - mae: 1.8240 - val_loss: 1.9057 - val_mae: 1.9057 - learning_rate: 5.0000e-04\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 15: val_loss did not improve from 1.58867\n",
      "30/30 - 42s - 1s/step - loss: 1.8581 - mae: 1.8581 - val_loss: 1.8882 - val_mae: 1.8882 - learning_rate: 5.0000e-04\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 16: val_loss improved from 1.58867 to 1.45228, saving model to ./best_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 - 41s - 1s/step - loss: 1.8555 - mae: 1.8555 - val_loss: 1.4523 - val_mae: 1.4523 - learning_rate: 5.0000e-04\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 17: val_loss did not improve from 1.45228\n",
      "30/30 - 43s - 1s/step - loss: 1.8842 - mae: 1.8842 - val_loss: 1.4677 - val_mae: 1.4677 - learning_rate: 5.0000e-04\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 18: val_loss did not improve from 1.45228\n",
      "30/30 - 42s - 1s/step - loss: 1.8418 - mae: 1.8418 - val_loss: 1.4598 - val_mae: 1.4598 - learning_rate: 5.0000e-04\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 19: val_loss did not improve from 1.45228\n",
      "30/30 - 37s - 1s/step - loss: 1.8559 - mae: 1.8559 - val_loss: 1.5175 - val_mae: 1.5175 - learning_rate: 5.0000e-04\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 20: val_loss did not improve from 1.45228\n",
      "30/30 - 37s - 1s/step - loss: 1.8437 - mae: 1.8437 - val_loss: 1.5700 - val_mae: 1.5700 - learning_rate: 5.0000e-04\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 21: val_loss did not improve from 1.45228\n",
      "\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "30/30 - 40s - 1s/step - loss: 1.8272 - mae: 1.8272 - val_loss: 1.4851 - val_mae: 1.4851 - learning_rate: 5.0000e-04\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 22: val_loss did not improve from 1.45228\n",
      "30/30 - 41s - 1s/step - loss: 1.8123 - mae: 1.8123 - val_loss: 1.4753 - val_mae: 1.4753 - learning_rate: 2.5000e-04\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 23: val_loss did not improve from 1.45228\n",
      "30/30 - 41s - 1s/step - loss: 1.8982 - mae: 1.8982 - val_loss: 1.4794 - val_mae: 1.4794 - learning_rate: 2.5000e-04\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 24: val_loss did not improve from 1.45228\n",
      "30/30 - 37s - 1s/step - loss: 1.8016 - mae: 1.8016 - val_loss: 1.5773 - val_mae: 1.5773 - learning_rate: 2.5000e-04\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 25: val_loss did not improve from 1.45228\n",
      "30/30 - 38s - 1s/step - loss: 1.8051 - mae: 1.8051 - val_loss: 1.4916 - val_mae: 1.4916 - learning_rate: 2.5000e-04\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 26: val_loss did not improve from 1.45228\n",
      "\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "30/30 - 38s - 1s/step - loss: 1.8217 - mae: 1.8217 - val_loss: 1.4619 - val_mae: 1.4619 - learning_rate: 2.5000e-04\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 27: val_loss did not improve from 1.45228\n",
      "30/30 - 38s - 1s/step - loss: 1.8054 - mae: 1.8054 - val_loss: 1.4830 - val_mae: 1.4830 - learning_rate: 1.2500e-04\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 28: val_loss did not improve from 1.45228\n",
      "30/30 - 37s - 1s/step - loss: 1.8410 - mae: 1.8410 - val_loss: 1.4729 - val_mae: 1.4729 - learning_rate: 1.2500e-04\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 29: val_loss did not improve from 1.45228\n",
      "30/30 - 38s - 1s/step - loss: 1.8359 - mae: 1.8359 - val_loss: 1.4560 - val_mae: 1.4560 - learning_rate: 1.2500e-04\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 30: val_loss did not improve from 1.45228\n",
      "30/30 - 38s - 1s/step - loss: 1.7663 - mae: 1.7663 - val_loss: 1.4717 - val_mae: 1.4717 - learning_rate: 1.2500e-04\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 31: val_loss did not improve from 1.45228\n",
      "\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "30/30 - 37s - 1s/step - loss: 1.8639 - mae: 1.8639 - val_loss: 1.4727 - val_mae: 1.4727 - learning_rate: 1.2500e-04\n",
      "Epoch 31: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    }
   ],
   "source": [
    "model = build_lstm_model()\n",
    "model.summary()\n",
    "OUT_DIR = \"./\"\n",
    "# ----------------- Compile -----------------\n",
    "opt = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "model.compile(optimizer=opt, loss=\"mae\", metrics=[\"mae\"])\n",
    "\n",
    "# ----------------- Callbacks -----------------\n",
    "checkpoint_path = os.path.join(OUT_DIR, \"best_model.h5\")\n",
    "cb_early = callbacks.EarlyStopping(monitor=\"val_loss\", patience=PATIENCE_ES, restore_best_weights=True, verbose=1)\n",
    "cb_checkpoint = callbacks.ModelCheckpoint(checkpoint_path, monitor=\"val_loss\", save_best_only=True, verbose=1)\n",
    "cb_reduce = callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=PATIENCE_RLR, verbose=1, min_lr=1e-6)\n",
    "\n",
    "# Also save training logs\n",
    "history_path = os.path.join(OUT_DIR, \"history.json\")\n",
    "\n",
    "# ----------------- Fit -----------------\n",
    "history = model.fit(\n",
    "    data, valence,\n",
    "    validation_split = 0.2,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    callbacks=[cb_early, cb_checkpoint, cb_reduce],\n",
    "    verbose=2,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AutoKeras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 01m 15s]\n",
      "val_loss: 2211255040.0\n",
      "\n",
      "Best val_loss So Far: 261253200.0\n",
      "Total elapsed time: 00h 05m 03s\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "False             |False             |general_block_1/dense_block_1/use_batchnorm\n",
      "2                 |2                 |general_block_1/dense_block_1/num_layers\n",
      "32                |32                |general_block_1/dense_block_1/units_0\n",
      "0                 |0                 |general_block_1/dense_block_1/dropout\n",
      "32                |32                |general_block_1/dense_block_1/units_1\n",
      "0                 |0                 |regression_head_1/dropout\n",
      "0.25              |0.25              |regression_head_2/dropout\n",
      "adam              |adam              |optimizer\n",
      "0.0001            |0.001             |learning_rate\n",
      "\n",
      "Epoch 1/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 339ms/step - loss: 3225550592.0000 - regression_head_1_loss: 862437376.0000 - regression_head_1_mse: 862437312.0000 - regression_head_2_loss: 2363112960.0000 - regression_head_2_mse: 2363113216.0000 - val_loss: 91592520.0000 - val_regression_head_1_loss: 32945822.0000 - val_regression_head_1_mse: 32945820.0000 - val_regression_head_2_loss: 58646696.0000 - val_regression_head_2_mse: 58646696.0000\n",
      "Epoch 2/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 181ms/step - loss: 4688658944.0000 - regression_head_1_loss: 1703591168.0000 - regression_head_1_mse: 1703591040.0000 - regression_head_2_loss: 2985067776.0000 - regression_head_2_mse: 2985068032.0000 - val_loss: 364580768.0000 - val_regression_head_1_loss: 145160768.0000 - val_regression_head_1_mse: 145160768.0000 - val_regression_head_2_loss: 219420032.0000 - val_regression_head_2_mse: 219420032.0000\n",
      "Epoch 3/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 36536778752.0000 - regression_head_1_loss: 11711113216.0000 - regression_head_1_mse: 11711112192.0000 - regression_head_2_loss: 24825665536.0000 - regression_head_2_mse: 24825665536.0000 - val_loss: 307351328.0000 - val_regression_head_1_loss: 62037596.0000 - val_regression_head_1_mse: 62037596.0000 - val_regression_head_2_loss: 245313744.0000 - val_regression_head_2_mse: 245313744.0000\n",
      "Epoch 4/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 87ms/step - loss: 21961535488.0000 - regression_head_1_loss: 1421015936.0000 - regression_head_1_mse: 1421016192.0000 - regression_head_2_loss: 20540518400.0000 - regression_head_2_mse: 20540520448.0000 - val_loss: 547996224.0000 - val_regression_head_1_loss: 125494488.0000 - val_regression_head_1_mse: 125494496.0000 - val_regression_head_2_loss: 422501728.0000 - val_regression_head_2_mse: 422501696.0000\n",
      "Epoch 5/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 64ms/step - loss: 17963124736.0000 - regression_head_1_loss: 9212370944.0000 - regression_head_1_mse: 9212369920.0000 - regression_head_2_loss: 8750754816.0000 - regression_head_2_mse: 8750753792.0000 - val_loss: 211072528.0000 - val_regression_head_1_loss: 106807944.0000 - val_regression_head_1_mse: 106807952.0000 - val_regression_head_2_loss: 104264576.0000 - val_regression_head_2_mse: 104264584.0000\n",
      "Epoch 6/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - loss: 20778158080.0000 - regression_head_1_loss: 15621957632.0000 - regression_head_1_mse: 15621957632.0000 - regression_head_2_loss: 5156203008.0000 - regression_head_2_mse: 5156203008.0000 - val_loss: 260049600.0000 - val_regression_head_1_loss: 79814248.0000 - val_regression_head_1_mse: 79814248.0000 - val_regression_head_2_loss: 180235328.0000 - val_regression_head_2_mse: 180235344.0000\n",
      "Epoch 7/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 117ms/step - loss: 18083936256.0000 - regression_head_1_loss: 766260992.0000 - regression_head_1_mse: 766260928.0000 - regression_head_2_loss: 17317677056.0000 - regression_head_2_mse: 17317675008.0000 - val_loss: 93078320.0000 - val_regression_head_1_loss: 44408788.0000 - val_regression_head_1_mse: 44408792.0000 - val_regression_head_2_loss: 48669528.0000 - val_regression_head_2_mse: 48669528.0000\n",
      "Epoch 8/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 88ms/step - loss: 9099354112.0000 - regression_head_1_loss: 451431168.0000 - regression_head_1_mse: 451431200.0000 - regression_head_2_loss: 8647922688.0000 - regression_head_2_mse: 8647921664.0000 - val_loss: 94667448.0000 - val_regression_head_1_loss: 24482062.0000 - val_regression_head_1_mse: 24482064.0000 - val_regression_head_2_loss: 70185384.0000 - val_regression_head_2_mse: 70185384.0000\n",
      "Epoch 9/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - loss: 10277106688.0000 - regression_head_1_loss: 119163864.0000 - regression_head_1_mse: 119163880.0000 - regression_head_2_loss: 10157943808.0000 - regression_head_2_mse: 10157943808.0000 - val_loss: 79329696.0000 - val_regression_head_1_loss: 50363404.0000 - val_regression_head_1_mse: 50363404.0000 - val_regression_head_2_loss: 28966300.0000 - val_regression_head_2_mse: 28966300.0000\n",
      "Epoch 10/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - loss: 9136422912.0000 - regression_head_1_loss: 373817536.0000 - regression_head_1_mse: 373817568.0000 - regression_head_2_loss: 8762606592.0000 - regression_head_2_mse: 8762606592.0000 - val_loss: 118060080.0000 - val_regression_head_1_loss: 36189960.0000 - val_regression_head_1_mse: 36189964.0000 - val_regression_head_2_loss: 81870136.0000 - val_regression_head_2_mse: 81870136.0000\n",
      "Epoch 11/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 146ms/step - loss: 8711671808.0000 - regression_head_1_loss: 5715210752.0000 - regression_head_1_mse: 5715210752.0000 - regression_head_2_loss: 2996460800.0000 - regression_head_2_mse: 2996460800.0000 - val_loss: 102424824.0000 - val_regression_head_1_loss: 32420824.0000 - val_regression_head_1_mse: 32420824.0000 - val_regression_head_2_loss: 70003992.0000 - val_regression_head_2_mse: 70003992.0000\n",
      "Epoch 12/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 139ms/step - loss: 3427588352.0000 - regression_head_1_loss: 135750704.0000 - regression_head_1_mse: 135750704.0000 - regression_head_2_loss: 3291837952.0000 - regression_head_2_mse: 3291837952.0000 - val_loss: 101854344.0000 - val_regression_head_1_loss: 30712840.0000 - val_regression_head_1_mse: 30712842.0000 - val_regression_head_2_loss: 71141512.0000 - val_regression_head_2_mse: 71141512.0000\n",
      "Epoch 13/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 276ms/step - loss: 1286477312.0000 - regression_head_1_loss: 163369184.0000 - regression_head_1_mse: 163369200.0000 - regression_head_2_loss: 1123108224.0000 - regression_head_2_mse: 1123108224.0000 - val_loss: 62665288.0000 - val_regression_head_1_loss: 22614244.0000 - val_regression_head_1_mse: 22614244.0000 - val_regression_head_2_loss: 40051040.0000 - val_regression_head_2_mse: 40051044.0000\n",
      "Epoch 14/100\n",
      "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 611076864.0000 - regression_head_1_loss: 125314504.0000 - regression_head_1_mse: 125314504.0000 - regression_head_2_loss: 485762336.0000 - regression_head_2_mse: 485762336.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[117], line 12\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m ak\u001b[39m.\u001b[39mAutoModel(\n\u001b[1;32m      3\u001b[0m     inputs\u001b[39m=\u001b[39m[ak\u001b[39m.\u001b[39mInput()],\n\u001b[1;32m      4\u001b[0m     outputs\u001b[39m=\u001b[39m[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     max_trials\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[1;32m     11\u001b[0m \u001b[39m# Fit the model with prepared data.\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     13\u001b[0m     [data],\n\u001b[1;32m     14\u001b[0m     [valence, arousal],\n\u001b[1;32m     15\u001b[0m     epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m,\n\u001b[1;32m     16\u001b[0m     batch_size\u001b[39m=\u001b[39;49m\u001b[39m50\u001b[39;49m,\n\u001b[1;32m     17\u001b[0m     validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m\n\u001b[1;32m     18\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autokeras/auto_model.py:303\u001b[0m, in \u001b[0;36mAutoModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, callbacks, validation_split, validation_data, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m validation_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m validation_split:\n\u001b[1;32m    299\u001b[0m     dataset, validation_data \u001b[39m=\u001b[39m data_utils\u001b[39m.\u001b[39msplit_dataset(\n\u001b[1;32m    300\u001b[0m         dataset, validation_split\n\u001b[1;32m    301\u001b[0m     )\n\u001b[0;32m--> 303\u001b[0m history \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    304\u001b[0m     x\u001b[39m=\u001b[39;49mdataset,\n\u001b[1;32m    305\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    306\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    307\u001b[0m     validation_data\u001b[39m=\u001b[39;49mvalidation_data,\n\u001b[1;32m    308\u001b[0m     validation_split\u001b[39m=\u001b[39;49mvalidation_split,\n\u001b[1;32m    309\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    310\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    311\u001b[0m )\n\u001b[1;32m    313\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autokeras/engine/tuner.py:202\u001b[0m, in \u001b[0;36mAutoTuner.search\u001b[0;34m(self, epochs, callbacks, validation_split, verbose, **fit_kwargs)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[1;32m    201\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mupdate_space(hp)\n\u001b[0;32m--> 202\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m    203\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m    204\u001b[0m     callbacks\u001b[39m=\u001b[39;49mnew_callbacks,\n\u001b[1;32m    205\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m    206\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs\n\u001b[1;32m    207\u001b[0m )\n\u001b[1;32m    209\u001b[0m \u001b[39m# Train the best model use validation data.\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[39m# Train the best model with enough number of epochs.\u001b[39;00m\n\u001b[1;32m    211\u001b[0m \u001b[39mif\u001b[39;00m validation_split \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mor\u001b[39;00m early_stopping_inserted:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:234\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    233\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 234\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_try_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    235\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    236\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:274\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_try_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m    273\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 274\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_and_update_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    275\u001b[0m         trial\u001b[39m.\u001b[39mstatus \u001b[39m=\u001b[39m trial_module\u001b[39m.\u001b[39mTrialStatus\u001b[39m.\u001b[39mCOMPLETED\n\u001b[1;32m    276\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras_tuner/engine/base_tuner.py:239\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m_run_and_update_trial\u001b[39m(\u001b[39mself\u001b[39m, trial, \u001b[39m*\u001b[39mfit_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 239\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    240\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mget_trial(trial\u001b[39m.\u001b[39mtrial_id)\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mexists(\n\u001b[1;32m    241\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname\n\u001b[1;32m    242\u001b[0m     ):\n\u001b[1;32m    243\u001b[0m         \u001b[39m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[39m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         \u001b[39m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    246\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    247\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe use case of calling \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    248\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m             stacklevel\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m,\n\u001b[1;32m    255\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras_tuner/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    316\u001b[0m     histories\u001b[39m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[39mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autokeras/engine/tuner.py:102\u001b[0m, in \u001b[0;36mAutoTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m     98\u001b[0m pipeline\u001b[39m.\u001b[39msave(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pipeline_path(trial\u001b[39m.\u001b[39mtrial_id))\n\u001b[1;32m    100\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39madapt(model, kwargs[\u001b[39m\"\u001b[39m\u001b[39mx\u001b[39m\u001b[39m\"\u001b[39m])\n\u001b[0;32m--> 102\u001b[0m _, history \u001b[39m=\u001b[39m utils\u001b[39m.\u001b[39;49mfit_with_adaptive_batch_size(\n\u001b[1;32m    103\u001b[0m     model, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mbatch_size, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    104\u001b[0m )\n\u001b[1;32m    105\u001b[0m \u001b[39mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autokeras/utils/utils.py:69\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size\u001b[0;34m(model, batch_size, **fit_kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[0;32m---> 69\u001b[0m     history \u001b[39m=\u001b[39m run_with_adaptive_batch_size(\n\u001b[1;32m     70\u001b[0m         batch_size, \u001b[39mlambda\u001b[39;49;00m \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs: model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autokeras/utils/utils.py:82\u001b[0m, in \u001b[0;36mrun_with_adaptive_batch_size\u001b[0;34m(batch_size, func, **fit_kwargs)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mwhile\u001b[39;00m batch_size \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     81\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 82\u001b[0m         history \u001b[39m=\u001b[39m func(x\u001b[39m=\u001b[39;49mx, validation_data\u001b[39m=\u001b[39;49mvalidation_data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m     83\u001b[0m         \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m     84\u001b[0m     \u001b[39mexcept\u001b[39;00m tf\u001b[39m.\u001b[39merrors\u001b[39m.\u001b[39mResourceExhaustedError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/autokeras/utils/utils.py:70\u001b[0m, in \u001b[0;36mfit_with_adaptive_batch_size.<locals>.<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfit_with_adaptive_batch_size\u001b[39m(model, batch_size, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs):\n\u001b[1;32m     69\u001b[0m     history \u001b[39m=\u001b[39m run_with_adaptive_batch_size(\n\u001b[0;32m---> 70\u001b[0m         batch_size, \u001b[39mlambda\u001b[39;00m \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs), \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_kwargs\n\u001b[1;32m     71\u001b[0m     )\n\u001b[1;32m     72\u001b[0m     \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:401\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m_eval_epoch_iterator\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_epoch_iterator \u001b[39m=\u001b[39m TFEpochIterator(\n\u001b[1;32m    392\u001b[0m         x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m    393\u001b[0m         y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m         shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    400\u001b[0m     )\n\u001b[0;32m--> 401\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m    402\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m    403\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m    404\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m    405\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m    406\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m    407\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m    408\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    409\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m    410\u001b[0m )\n\u001b[1;32m    411\u001b[0m val_logs \u001b[39m=\u001b[39m {\n\u001b[1;32m    412\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()\n\u001b[1;32m    413\u001b[0m }\n\u001b[1;32m    414\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    118\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:489\u001b[0m, in \u001b[0;36mTensorFlowTrainer.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[39mfor\u001b[39;00m begin_step, end_step, iterator \u001b[39min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    488\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_begin(begin_step)\n\u001b[0;32m--> 489\u001b[0m     logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m    490\u001b[0m     callbacks\u001b[39m.\u001b[39mon_test_batch_end(end_step, logs)\n\u001b[1;32m    491\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstop_evaluating:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/src/backend/tensorflow/trainer.py:220\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mfunction\u001b[39m(iterator):\n\u001b[1;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\n\u001b[1;32m    218\u001b[0m         iterator, (tf\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mIterator, tf\u001b[39m.\u001b[39mdistribute\u001b[39m.\u001b[39mDistributedIterator)\n\u001b[1;32m    219\u001b[0m     ):\n\u001b[0;32m--> 220\u001b[0m         opt_outputs \u001b[39m=\u001b[39m multi_step_on_iterator(iterator)\n\u001b[1;32m    221\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m opt_outputs\u001b[39m.\u001b[39mhas_value():\n\u001b[1;32m    222\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[39m=\u001b[39m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    879\u001b[0m     args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_variable_creation_config\n\u001b[1;32m    880\u001b[0m )\n\u001b[1;32m    881\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall_preflattened(args)\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[39mdef\u001b[39;00m\u001b[39m \u001b[39m\u001b[39mcall_preflattened\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcall_flat(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    217\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    252\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    253\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    254\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1689\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1690\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1691\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1692\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1693\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1694\u001b[0m   )\n\u001b[1;32m   1695\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the multi with multiple inputs and outputs.\n",
    "model = ak.AutoModel(\n",
    "    inputs=[ak.Input()],\n",
    "    outputs=[\n",
    "        ak.RegressionHead(metrics=[\"mse\"]),\n",
    "        ak.RegressionHead(metrics=[\"mse\"])\n",
    "    ],\n",
    "    overwrite=True,\n",
    "    max_trials=5,\n",
    ")\n",
    "# Fit the model with prepared data.\n",
    "model.fit(\n",
    "    [data],\n",
    "    [valence, arousal],\n",
    "    epochs=100,\n",
    "    batch_size=50,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9 (v3.10.9:1dd9be6584, Dec  6 2022, 14:37:36) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
