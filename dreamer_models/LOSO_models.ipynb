{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216b041a",
   "metadata": {},
   "source": [
    "# Train and Apply Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867a2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.model_training import (\n",
    "    omit_patient_video,\n",
    "    single_user_split,\n",
    "    train_lstm,\n",
    "    train_random_forest,\n",
    "    build_lstm_sequences\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ML import utils\n",
    "import sys\n",
    "import random\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "207643ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_list = [5, 18]\n",
    "remove_list = []\n",
    "\n",
    "def balance(X, y, seed=5):\n",
    "    c = y.value_counts()\n",
    "    if c.get(\"high\", 0) == c.get(\"low\", 0):\n",
    "        return X.reset_index(drop=True), y.reset_index(drop=True)\n",
    "    maj = c.idxmax()\n",
    "    m = c.min()\n",
    "    keep = y[y != maj].index.union(y[y == maj].sample(m, random_state=seed).index)\n",
    "    return X.loc[keep].reset_index(drop=True), y.loc[keep].reset_index(drop=True)\n",
    "\n",
    "# subjects = [i for i in range(0, 23)]\n",
    "subjects = [15]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8239f8d",
   "metadata": {},
   "source": [
    "## LSTM CV Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e2c18",
   "metadata": {},
   "source": [
    "This is currently running LOSO CV, by removing 18 videos (all) from each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71dbfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting global hyperparameter search...\n",
      "\n",
      "Held-out patient: 15 | Held-out (patient, video) trials: [(15, 0), (15, 1), (15, 2), (15, 3), (15, 4), (15, 5), (15, 6), (15, 7), (15, 8), (15, 9), (15, 10), (15, 11), (15, 12), (15, 13), (15, 14), (15, 15), (15, 16), (15, 17)] | Excluded users: []\n",
      "y_train counts: [223 173]\n",
      "y_test counts: [10  8]\n",
      "X_train_arr shape: (396, 196, 476)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 815ms/step\n",
      "0.6666666666666666\n",
      "\n",
      "Confusion Matrix (subject):\n",
      "[[10  0]\n",
      " [ 6  2]]\n",
      "Params lr=0.0001, epochs=100, units=512, batch_size=128, timesteps=None -> mean acc across subjects = 0.6667\n",
      "\n",
      "Best universal hyperparameters:\n",
      "{'lr': 0.0001, 'epochs': 100, 'units': 512, 'batch_size': 128, 'timesteps': None}\n",
      "Mean accuracy across subjects (tuning): 0.6667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    \"lr\": [0.0001],\n",
    "    \"epochs\": [100],\n",
    "    \"units\": [512],\n",
    "    \"batch_size\": [128],\n",
    "    \"timesteps\": [None]\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_mean_acc = -float(\"inf\")\n",
    "\n",
    "print(\"Starting global hyperparameter search...\\n\")\n",
    "\n",
    "for lr, epochs, units, batch_size, timesteps in product(\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"epochs\"],\n",
    "    param_grid[\"units\"],\n",
    "    param_grid[\"batch_size\"],\n",
    "    param_grid[\"timesteps\"],\n",
    "):\n",
    "    combo_accs = []\n",
    "    for i in subjects:\n",
    "        relabel = False\n",
    "        while True:\n",
    "            while True:\n",
    "                X_train_df, X_test_df, arousal_train, arousal_test = omit_patient_video(\n",
    "                    target=\"arousal\",\n",
    "                    selected_user=i,\n",
    "                    trials=18,\n",
    "                    # holdout_videos=[2, 10, 15],\n",
    "                    exclude_users=remove_list,\n",
    "                    filename=\"datasets/features_table.csv\",\n",
    "                    relabel=relabel,\n",
    "                )\n",
    "\n",
    "                features = utils.filter_features(\n",
    "                    X_train_df.columns,\n",
    "                    remove_bands=[\"gamma\"],\n",
    "                )\n",
    "                features = [c for c in features if c in X_train_df.columns]\n",
    "                features.remove(\"arousal\")\n",
    "                features.remove(\"valence\")\n",
    "                features.remove(\"patient_index\")\n",
    "                features.remove(\"video_index\")\n",
    "\n",
    "                # Build sequence-level data (trials = (patient, video))\n",
    "                X_train_seq, y_train_seq = build_lstm_sequences(\n",
    "                    X_train_df,\n",
    "                    features,\n",
    "                    target_col=\"arousal\",\n",
    "                    thresh=3.8,\n",
    "                    fixed_T=timesteps,\n",
    "                )\n",
    "                X_test_seq, y_test_seq = build_lstm_sequences(\n",
    "                    X_test_df,\n",
    "                    features,\n",
    "                    target_col=\"arousal\",\n",
    "                    thresh=3.8,\n",
    "                    fixed_T=timesteps\n",
    "                )\n",
    "\n",
    "                minority = (y_train_seq == 1.0).sum() < (y_train_seq == 0.0).sum()\n",
    "                maj_label = 0.0 if minority else 1.0\n",
    "                min_label = 1.0 - maj_label\n",
    "\n",
    "                idx_maj = np.where(y_train_seq == maj_label)[0]\n",
    "                idx_min = np.where(y_train_seq == min_label)[0]\n",
    "\n",
    "                if len(idx_min) == 0:\n",
    "                    # no samples of one class, redo split\n",
    "                    print(\"No minority class in this split, re-drawing...\")\n",
    "                    continue\n",
    "\n",
    "                # reps = int(np.ceil(len(idx_maj) / len(idx_min)))\n",
    "                # idx_min_upsampled = np.tile(idx_min, reps)[: len(idx_maj)]\n",
    "\n",
    "                # idx_balanced = np.concatenate([idx_maj, idx_min_upsampled])\n",
    "                # np.random.shuffle(idx_balanced)\n",
    "\n",
    "                # X_train_bal = X_train_seq[idx_balanced]\n",
    "                # y_train_bal = y_train_seq[idx_balanced]\n",
    "\n",
    "                print(\"y_train counts:\", np.bincount(y_train_seq.astype(int)))\n",
    "                print(\"y_test counts:\", np.bincount(y_test_seq.astype(int)))\n",
    "\n",
    "                break\n",
    "\n",
    "            lstm, X_test_eval, y_test_eval = train_lstm(\n",
    "                X_train_seq,\n",
    "                X_test_seq,\n",
    "                y_train_seq,\n",
    "                y_test_seq,\n",
    "                lr=lr,\n",
    "                epochs=epochs,\n",
    "                units=units,\n",
    "                batch_size=batch_size,\n",
    "                dropout=0.4,\n",
    "                recurrent_dropout=0.2,\n",
    "                bidirectional=True,\n",
    "            )\n",
    "            y_prob = lstm.predict(X_test_eval).ravel()\n",
    "            arousal_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "            acc = accuracy_score(y_test_eval, arousal_pred)\n",
    "            print(acc)\n",
    "            relabel = False\n",
    "            break\n",
    "\n",
    "        combo_accs.append(float(acc))\n",
    "\n",
    "        print(\"\\nConfusion Matrix (subject):\")\n",
    "        print(confusion_matrix(y_test_eval, arousal_pred))\n",
    "    mean_acc = float(np.mean(combo_accs))\n",
    "    print(\n",
    "        f\"Params lr={lr}, epochs={epochs}, units={units}, batch_size={batch_size}, timesteps={timesteps} \"\n",
    "        f\"-> mean acc across subjects = {mean_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    if mean_acc > best_mean_acc:\n",
    "        best_lstm = lstm\n",
    "        best_mean_acc = mean_acc\n",
    "        best_params = {\n",
    "            \"lr\": lr,\n",
    "            \"epochs\": epochs,\n",
    "            \"units\": units,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"timesteps\": timesteps\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"\\nBest universal hyperparameters:\")\n",
    "print(best_params)\n",
    "print(f\"Mean accuracy across subjects (tuning): {best_mean_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40fcf5",
   "metadata": {},
   "source": [
    "### Fine-tune for User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b26fff08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<InputLayer name=input_layer, built=True>, <Bidirectional name=bidirectional, built=True>, <Dense name=dense, built=True>, <Dropout name=dropout, built=True>, <Dense name=dense_1, built=True>]\n"
     ]
    }
   ],
   "source": [
    "print(best_lstm.layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d77aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting per-user fine-tuning hyperparameter search...\n",
      "\n",
      "Testing combo: lr=0.0001, batch_size=32, epochs=50, patience=3, layers=1, units=64\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import callbacks\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from itertools import product\n",
    "\n",
    "param_grid = {\n",
    "    \"lr\": [0.0001],\n",
    "    \"epochs\": [50],\n",
    "    \"batch_size\": [32],\n",
    "    \"patience\": [3],\n",
    "    \"layers\": [1, 2],\n",
    "    \"units\": [64, 128],\n",
    "}\n",
    "\n",
    "T_SIZE = 196\n",
    "N_RUNS = 1\n",
    "SELECTED_USER = 15\n",
    "TRIALS = [i for i in range(0, 18, 2)]\n",
    "\n",
    "best_params = None\n",
    "best_mean_acc = -np.inf\n",
    "\n",
    "print(\"Starting per-user fine-tuning hyperparameter search...\\n\")\n",
    "\n",
    "for lr, epochs, batch_size, patience, layers, units in product(\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"epochs\"],\n",
    "    param_grid[\"batch_size\"],\n",
    "    param_grid[\"patience\"],\n",
    "    param_grid[\"layers\"],\n",
    "    param_grid[\"units\"],\n",
    "):\n",
    "\n",
    "    combo_accs = []\n",
    "\n",
    "    print(\n",
    "        f\"Testing combo: lr={lr}, batch_size={batch_size}, \"\n",
    "        f\"epochs={epochs}, patience={patience}, layers={layers}, units={units}\"\n",
    "    )\n",
    "\n",
    "    for run in range(N_RUNS):\n",
    "        (\n",
    "            X_user_train_df,\n",
    "            X_user_test_df,\n",
    "            arousal_user_train,\n",
    "            arousal_user_test,\n",
    "        ) = single_user_split(\n",
    "            target=\"arousal\",\n",
    "            selected_user=SELECTED_USER,\n",
    "            holdout_videos=TRIALS,\n",
    "            k_holdouts=9,\n",
    "            filename=\"datasets/features_table.csv\",\n",
    "        )\n",
    "\n",
    "        X_user_train_seq, y_user_train_seq = build_lstm_sequences(\n",
    "            X_user_train_df,\n",
    "            feature_cols=features,\n",
    "            target_col=\"arousal\",\n",
    "            thresh=3.8,\n",
    "            fixed_T=T_SIZE,\n",
    "        )\n",
    "        X_user_test_seq, y_user_test_seq = build_lstm_sequences(\n",
    "            X_user_test_df,\n",
    "            feature_cols=features,\n",
    "            target_col=\"arousal\",\n",
    "            thresh=3.8,\n",
    "            fixed_T=T_SIZE,\n",
    "        )\n",
    "\n",
    "        base_model = clone_model(best_lstm)\n",
    "        base_model.build(best_lstm.input_shape)\n",
    "        base_model.set_weights(best_lstm.get_weights())\n",
    "\n",
    "        for layer in base_model.layers[:-layers]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        inputs = tf.keras.Input(shape=best_lstm.input_shape[1:])\n",
    "        x = base_model(inputs, training=True)\n",
    "        x = tf.keras.layers.Dense(units, activation=\"relu\")(x)\n",
    "        outputs = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "        user_model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "        opt = optimizers.Adam(learning_rate=lr)\n",
    "        user_model.compile(optimizer=opt,\n",
    "                           loss=\"binary_crossentropy\",\n",
    "                           metrics=[\"accuracy\"])\n",
    "\n",
    "        es = callbacks.EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=patience,\n",
    "            restore_best_weights=True,\n",
    "        )\n",
    "\n",
    "        user_model.fit(\n",
    "            X_user_train_seq,\n",
    "            y_user_train_seq,\n",
    "            validation_split=0.2,\n",
    "            epochs=epochs,\n",
    "            batch_size=batch_size,\n",
    "            callbacks=[es],\n",
    "            verbose=0,\n",
    "        )\n",
    "\n",
    "        y_prob = user_model.predict(X_user_train_seq).ravel()\n",
    "        print(y_prob)\n",
    "        arousal_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_user_train_seq, arousal_pred)\n",
    "        cm = confusion_matrix(y_user_train_seq, arousal_pred)\n",
    "        print(\"Confusion matrix:\\n\", cm)\n",
    "\n",
    "        combo_accs.append(acc)\n",
    "\n",
    "    mean_acc = np.mean(combo_accs)\n",
    "    std_acc = np.std(combo_accs)\n",
    "    print(f\"  -> mean acc over {N_RUNS} runs: {mean_acc:.4f} (std={std_acc:.4f})\\n\")\n",
    "\n",
    "    if mean_acc > best_mean_acc:\n",
    "        best_mean_acc = mean_acc\n",
    "        best_params = {\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"patience\": patience,\n",
    "            \"units\": units,\n",
    "            \"layers\": layers,\n",
    "        }\n",
    "\n",
    "print(f\"Best mean test accuracy: {best_mean_acc:.4f}\\n\")\n",
    "print(best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1be913",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
