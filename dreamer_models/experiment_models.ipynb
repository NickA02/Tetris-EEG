{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216b041a",
   "metadata": {},
   "source": [
    "# Train and Apply Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867a2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.model_training import (\n",
    "    omit_patient_video,\n",
    "    single_user_split,\n",
    "    train_lstm,\n",
    "    train_random_forest,\n",
    "    build_lstm_sequences\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ML import utils\n",
    "import sys\n",
    "import random\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207643ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_list = [0, 1, 2, 4, 5, 8, 9, 10, 11, 14, 16, 17, 18, 22]\n",
    "remove_list = []\n",
    "\n",
    "def balance(X, y, seed=5):\n",
    "    c = y.value_counts()\n",
    "    if c.get(\"high\", 0) == c.get(\"low\", 0):\n",
    "        return X.reset_index(drop=True), y.reset_index(drop=True)\n",
    "    maj = c.idxmax()\n",
    "    m = c.min()\n",
    "    keep = y[y != maj].index.union(y[y == maj].sample(m, random_state=seed).index)\n",
    "    return X.loc[keep].reset_index(drop=True), y.loc[keep].reset_index(drop=True)\n",
    "\n",
    "# subjects = [i for i in range(0, 23)]\n",
    "# subjects = [3]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa1894",
   "metadata": {},
   "source": [
    "## LSTM CV Optimizer - PSD features only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371e2c18",
   "metadata": {},
   "source": [
    "This is currently running LOSO CV, by removing 18 videos (all) from each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad1428d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_SIZE = 5\n",
    "subjects = []\n",
    "for i in range(0, CV_SIZE):\n",
    "    subjects.append(random.randint(0, 22))\n",
    "subjects = [20]\n",
    "\n",
    "param_grid = {\n",
    "    \"lr\": [0.0001],\n",
    "    \"epochs\": [100],\n",
    "    \"units\": [256],\n",
    "    \"batch_size\": [64],\n",
    "    \"timesteps\": [76],\n",
    "}\n",
    "\n",
    "best_params = None\n",
    "best_mean_acc = -float(\"inf\")\n",
    "\n",
    "print(\"Starting global hyperparameter search...\\n\")\n",
    "\n",
    "for lr, epochs, units, batch_size, timesteps in product(\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"epochs\"],\n",
    "    param_grid[\"units\"],\n",
    "    param_grid[\"batch_size\"],\n",
    "    param_grid[\"timesteps\"],\n",
    "):\n",
    "    combo_accs = []\n",
    "    for i in subjects:\n",
    "        relabel = False\n",
    "        while True:\n",
    "            while True:\n",
    "                X_train_df, X_test_df, arousal_train, arousal_test = omit_patient_video(\n",
    "                    target=\"arousal\",\n",
    "                    selected_user=i,\n",
    "                    trials=18,\n",
    "                    # holdout_videos=[2, 10, 15],\n",
    "                    exclude_users=remove_list,\n",
    "                    filename=\"datasets/experiment_features_table.csv\",\n",
    "                    relabel=relabel,\n",
    "                )\n",
    "\n",
    "                features = utils.filter_features(\n",
    "                    X_train_df.columns,\n",
    "                    remove_bands=[\"gamma\"],\n",
    "                )\n",
    "                features = [c for c in features if c in X_train_df.columns]\n",
    "                features.remove(\"arousal\")\n",
    "                features.remove(\"valence\")\n",
    "                features.remove(\"patient_index\")\n",
    "                features.remove(\"video_index\")\n",
    "\n",
    "                # Build sequence-level data (trials = (patient, video))\n",
    "                X_train_seq, y_train_seq = build_lstm_sequences(\n",
    "                    X_train_df,\n",
    "                    features,\n",
    "                    target_col=\"arousal\",\n",
    "                    thresh=3.8,\n",
    "                    fixed_T=timesteps,\n",
    "                )\n",
    "                X_test_seq, y_test_seq = build_lstm_sequences(\n",
    "                    X_test_df,\n",
    "                    features,\n",
    "                    target_col=\"arousal\",\n",
    "                    thresh=3.8,\n",
    "                    fixed_T=timesteps,\n",
    "                )\n",
    "\n",
    "                minority = (y_train_seq == 1.0).sum() < (y_train_seq == 0.0).sum()\n",
    "                maj_label = 0.0 if minority else 1.0\n",
    "                min_label = 1.0 - maj_label\n",
    "                n_pos = (y_train_seq == 1.0).sum()\n",
    "                n_neg = (y_train_seq == 1.0).sum()\n",
    "\n",
    "                idx_maj = np.where(y_train_seq == maj_label)[0]\n",
    "                idx_min = np.where(y_train_seq == min_label)[0]\n",
    "\n",
    "                if len(idx_min) == 0:\n",
    "                    # no samples of one class, redo split\n",
    "                    print(\"No minority class in this split, re-drawing...\")\n",
    "                    continue\n",
    "\n",
    "                # reps = int(np.ceil(len(idx_maj) / len(idx_min)))\n",
    "                # idx_min_upsampled = np.tile(idx_min, reps)[: len(idx_maj)]\n",
    "\n",
    "                # idx_balanced = np.concatenate([idx_maj, idx_min_upsampled])\n",
    "                # np.random.shuffle(idx_balanced)\n",
    "\n",
    "                # X_train_bal = X_train_seq[idx_balanced]\n",
    "                # y_train_bal = y_train_seq[idx_balanced]\n",
    "\n",
    "                print(\"y_train counts:\", np.bincount(y_train_seq.astype(int)))\n",
    "                print(\"y_test counts:\", np.bincount(y_test_seq.astype(int)))\n",
    "\n",
    "                break\n",
    "\n",
    "            lstm, X_test_eval, y_test_eval = train_lstm(\n",
    "                X_train_seq,\n",
    "                X_test_seq,\n",
    "                y_train_seq,\n",
    "                y_test_seq,\n",
    "                lr=lr,\n",
    "                epochs=epochs,\n",
    "                units=units,\n",
    "                batch_size=batch_size,\n",
    "                dropout=0.4,\n",
    "                recurrent_dropout=0,\n",
    "                bidirectional=True,\n",
    "            )\n",
    "            y_prob = lstm.predict(X_test_eval).ravel()\n",
    "            arousal_pred = (y_prob >= 0.5).astype(int) # TODO\n",
    "\n",
    "            acc = accuracy_score(y_test_eval, arousal_pred)\n",
    "            print(acc)\n",
    "            relabel = False\n",
    "            break\n",
    "\n",
    "        combo_accs.append(float(acc))\n",
    "\n",
    "        print(\"\\nConfusion Matrix (subject):\")\n",
    "        print(confusion_matrix(y_test_eval, arousal_pred))\n",
    "    mean_acc = float(np.mean(combo_accs))\n",
    "    print(\n",
    "        f\"Params lr={lr}, epochs={epochs}, units={units}, batch_size={batch_size}, timesteps={timesteps} \"\n",
    "        f\"-> mean acc across subjects = {mean_acc:.4f}\"\n",
    "    )\n",
    "\n",
    "    if mean_acc > best_mean_acc:\n",
    "        best_lstm = lstm\n",
    "        best_mean_acc = mean_acc\n",
    "        best_params = {\n",
    "            \"lr\": lr,\n",
    "            \"epochs\": epochs,\n",
    "            \"units\": units,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"timesteps\": timesteps,\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"\\nBest universal hyperparameters:\")\n",
    "print(256)\n",
    "print(f\"Mean accuracy across subjects (tuning): {best_mean_acc:.4f}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf40fcf5",
   "metadata": {},
   "source": [
    "### Fine-tune for User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d77aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import clone_model\n",
    "from tensorflow.keras import optimizers\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"lr\": [0.0001],\n",
    "    \"epochs\": [12, 25],\n",
    "    \"batch_size\": [64],\n",
    "    \"patience\": [8],\n",
    "    \"layers\": [1, 2],\n",
    "}\n",
    "\n",
    "T_SIZE = 76\n",
    "N_RUNS = 1\n",
    "SELECTED_USER = 20\n",
    "TRIALS = [i for i in range(8, 18)]\n",
    "\n",
    "best_params = None\n",
    "best_mean_acc = -np.inf\n",
    "\n",
    "print(\"Starting per-user fine-tuning hyperparameter search...\\n\")\n",
    "\n",
    "for lr, epochs, batch_size, patience, layers in product(\n",
    "    param_grid[\"lr\"],\n",
    "    param_grid[\"epochs\"],\n",
    "    param_grid[\"batch_size\"],\n",
    "    param_grid[\"patience\"],\n",
    "    param_grid[\"layers\"],\n",
    "):\n",
    "\n",
    "    combo_accs = []\n",
    "    combo_preds = []\n",
    "    combo_eval = []\n",
    "\n",
    "    print(\n",
    "        f\"Testing combo: lr={lr}, batch_size={batch_size}, \"\n",
    "        f\"epochs={epochs}, patience={patience}, layers={layers}\"\n",
    "    )\n",
    "\n",
    "    for run in range(N_RUNS):\n",
    "        (\n",
    "            X_user_train_df,\n",
    "            X_user_test_df,\n",
    "            arousal_user_train,\n",
    "            arousal_user_test,\n",
    "        ) = single_user_split(\n",
    "            target=\"arousal\",\n",
    "            selected_user=SELECTED_USER,\n",
    "            holdout_videos=TRIALS,\n",
    "            # holdout_videos=[run],\n",
    "            # k_holdouts=1,\n",
    "            filename=\"datasets/experiment_features_table.csv\",\n",
    "        )\n",
    "\n",
    "        X_user_train_seq, y_user_train_seq = build_lstm_sequences(\n",
    "            X_user_train_df,\n",
    "            feature_cols=features,\n",
    "            target_col=\"arousal\",\n",
    "            thresh=3.8,\n",
    "            fixed_T=T_SIZE,\n",
    "        )\n",
    "        X_user_test_seq, y_user_test_seq = build_lstm_sequences(\n",
    "            X_user_test_df,\n",
    "            feature_cols=features,\n",
    "            target_col=\"arousal\",\n",
    "            thresh=3.8,\n",
    "            fixed_T=T_SIZE,\n",
    "        )\n",
    "\n",
    "        user_model = clone_model(best_lstm)\n",
    "        user_model.build(best_lstm.input_shape)\n",
    "        user_model.set_weights(best_lstm.get_weights())\n",
    "\n",
    "        for layer in user_model.layers[:-layers]:\n",
    "            layer.trainable = False\n",
    "\n",
    "        user_model.compile(\n",
    "            optimizer=optimizers.Adam(learning_rate=lr),\n",
    "            loss=\"binary_crossentropy\",\n",
    "            metrics=[\"accuracy\"],\n",
    "        )\n",
    "\n",
    "        history = user_model.fit(\n",
    "            X_user_train_seq,\n",
    "            y_user_train_seq,\n",
    "            validation_split=0.2,\n",
    "            verbose=False,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            callbacks=[\n",
    "                tf.keras.callbacks.EarlyStopping(\n",
    "                    patience=patience,\n",
    "                    restore_best_weights=True,\n",
    "                    monitor=\"val_accuracy\",\n",
    "                )\n",
    "            ],\n",
    "        )\n",
    "        y_prob = user_model.predict(X_user_train_seq).ravel()\n",
    "        arousal_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "        acc = accuracy_score(y_user_train_seq, arousal_pred)\n",
    "        cm = confusion_matrix(y_user_train_seq, arousal_pred)\n",
    "        print(cm)\n",
    "\n",
    "        combo_accs.append(acc)\n",
    "        combo_preds.append(arousal_pred)\n",
    "        combo_eval.append(y_user_train_seq)\n",
    "\n",
    "    # print(confusion_matrix(combo_eval, combo_preds))\n",
    "    mean_acc = np.mean(combo_accs)\n",
    "    std_acc = np.std(combo_accs)\n",
    "    print(f\"  -> mean acc over {N_RUNS} runs: {mean_acc:.4f} \" f\"(std={std_acc:.4f})\\n\")\n",
    "    if mean_acc > best_mean_acc:\n",
    "        best_mean_acc = mean_acc\n",
    "        best_params = {\n",
    "            \"lr\": lr,\n",
    "            \"batch_size\": batch_size,\n",
    "            \"epochs\": epochs,\n",
    "            \"patience\": patience,\n",
    "            \"layers\": layers,\n",
    "        }\n",
    "\n",
    "print(\"\\nBest hyperparameters for user\", SELECTED_USER)\n",
    "print(best_params)\n",
    "print(f\"Best mean test accuracy: {best_mean_acc:.4f}\\n\")\n",
    "\n",
    "\n",
    "# Final evaluation with best hyperparams\n",
    "acc_list = []\n",
    "all_cm = np.zeros((2, 2), dtype=int)\n",
    "\n",
    "print(\"Running final evaluation with best hyperparameters...\\n\")\n",
    "\n",
    "for run in range(N_RUNS):\n",
    "    (\n",
    "        X_user_train_df,\n",
    "        X_user_test_df,\n",
    "        arousal_user_train,\n",
    "        arousal_user_test,\n",
    "    ) = single_user_split(\n",
    "        target=\"arousal\",\n",
    "        selected_user=SELECTED_USER,\n",
    "        k_holdouts=1,\n",
    "        filename=\"datasets/experiment_features_table.csv\",\n",
    "    )\n",
    "\n",
    "    X_user_train_seq, y_user_train_seq = build_lstm_sequences(\n",
    "        X_user_train_df,\n",
    "        feature_cols=features,\n",
    "        target_col=\"arousal\",\n",
    "        thresh=3.8,\n",
    "        fixed_T=T_SIZE,\n",
    "    )\n",
    "    X_user_test_seq, y_user_test_seq = build_lstm_sequences(\n",
    "        X_user_test_df,\n",
    "        feature_cols=features,\n",
    "        target_col=\"arousal\",\n",
    "        thresh=3.8,\n",
    "        fixed_T=T_SIZE,\n",
    "    )\n",
    "\n",
    "    print(f\"Run {run}\")\n",
    "    print(\"User train seq shape:\", X_user_train_seq.shape)\n",
    "    print(\"User test  seq shape:\", X_user_test_seq.shape)\n",
    "    print(\"y_train counts:\", np.bincount(y_user_train_seq.astype(int)))\n",
    "    print(\"y_test  counts:\", np.bincount(y_user_test_seq.astype(int)))\n",
    "\n",
    "    user_model = clone_model(best_lstm)\n",
    "    user_model.build(best_lstm.input_shape)\n",
    "    user_model.set_weights(best_lstm.get_weights())\n",
    "\n",
    "    for layer in user_model.layers[:-best_params[\"layers\"]]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    user_model.compile(\n",
    "        optimizer=optimizers.Adam(learning_rate=best_params[\"lr\"]),\n",
    "        loss=\"binary_crossentropy\",\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    history = user_model.fit(\n",
    "        X_user_train_seq,\n",
    "        y_user_train_seq,\n",
    "        validation_split=0.2,\n",
    "        verbose=False,\n",
    "        batch_size=best_params[\"batch_size\"],\n",
    "        epochs=best_params[\"epochs\"],\n",
    "        callbacks=[\n",
    "            tf.keras.callbacks.EarlyStopping(\n",
    "                patience=best_params[\"patience\"],\n",
    "                restore_best_weights=True,\n",
    "                monitor=\"val_accuracy\",\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    test_loss, test_acc = user_model.evaluate(\n",
    "        X_user_test_seq, y_user_test_seq, verbose=1\n",
    "    )\n",
    "\n",
    "    acc_list.append(test_acc)\n",
    "\n",
    "    y_prob = user_model.predict(X_user_test_seq, verbose=0).ravel()\n",
    "    y_pred = (y_prob >= 0.5).astype(\"int32\")\n",
    "\n",
    "    cm = confusion_matrix(y_user_test_seq.astype(\"int32\"), y_pred, labels=[0, 1])\n",
    "    all_cm += cm\n",
    "\n",
    "    print(\n",
    "        \"\\nOverall accuracy:\", accuracy_score(y_user_test_seq.astype(\"int32\"), y_pred)\n",
    "    )\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "acc_array = np.array(acc_list)\n",
    "print(f\"\\nMean user test accuracy over {len(acc_array)} runs: {acc_array.mean():.4f}\")\n",
    "print(f\"Std of user test accuracy over {len(acc_array)} runs: {acc_array.std():.4f}\")\n",
    "\n",
    "print(\"\\nPooled confusion matrix over all runs:\")\n",
    "print(all_cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc6ee14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
