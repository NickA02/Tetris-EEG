{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216b041a",
   "metadata": {},
   "source": [
    "# Train and Apply Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "867a2ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ML.model_training import (\n",
    "    train_lstm,\n",
    ")\n",
    "from ML.labels import build_video_rating_tables\n",
    "from ML.splits import single_user_split\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    confusion_matrix,\n",
    "    classification_report,\n",
    ")\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math, re, itertools\n",
    "from ML import utils\n",
    "import sys\n",
    "from IPython.display import clear_output\n",
    "from scipy.stats import pearsonr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b252c5",
   "metadata": {},
   "source": [
    "Generate all subsets of columns for parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0e8ffe9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arousal_train counts:\n",
      " low     605\n",
      "high    605\n",
      "Name: count, dtype: Int64\n",
      "arousal_test counts:\n",
      " high    196\n",
      "Name: count, dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, arousal_train, arousal_test = single_user_split(\n",
    "    target=\"arousal\", selected_user=0, k_holdouts=1\n",
    ")\n",
    "features = utils.filter_features(X_train.columns, remove_bands=[\"gamma\", \"delta\"])\n",
    "arousal_train = pd.Series(\n",
    "    np.where(arousal_train > 3.8, \"high\", \"low\"),\n",
    "    index=arousal_train.index,\n",
    "    dtype=\"string\",\n",
    ")\n",
    "arousal_test = pd.Series(\n",
    "    np.where(arousal_test > 3.8, \"high\", \"low\"),\n",
    "    index=arousal_test.index,\n",
    "    dtype=\"string\",\n",
    ")\n",
    "\n",
    "\n",
    "def balance(X, y, seed=5):\n",
    "    c = y.value_counts()\n",
    "    if c.get(\"high\", 0) == c.get(\"low\", 0):\n",
    "        return X.reset_index(drop=True), y.reset_index(drop=True)\n",
    "    maj = c.idxmax()\n",
    "    m = c.min()\n",
    "    keep = y[y != maj].index.union(y[y == maj].sample(m, random_state=seed).index)\n",
    "    return X.loc[keep].reset_index(drop=True), y.loc[keep].reset_index(drop=True)\n",
    "\n",
    "\n",
    "X_train, arousal_train = balance(X_train, arousal_train, seed=5)\n",
    "X_test, arousal_test = balance(X_test, arousal_test, seed=5)\n",
    "\n",
    "print(\"arousal_train counts:\\n\", arousal_train.value_counts(dropna=False))\n",
    "print(\"arousal_test counts:\\n\", arousal_test.value_counts(dropna=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c0eb3e",
   "metadata": {},
   "source": [
    "## LSTM LOO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "346be325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step\n",
      "Best: acc=1.000000 | f1=1.000000 | prec=1.000000 | rec=1.000000 | lr=0.0001 | epochs=10 | units=256 | batch_size=128\n",
      "\n",
      "Confusion Matrix (pooled):\n",
      "[[92]]\n",
      "\n",
      "Classification Report (pooled):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00        92\n",
      "\n",
      "    accuracy                           1.00        92\n",
      "   macro avg       1.00      1.00      1.00        92\n",
      "weighted avg       1.00      1.00      1.00        92\n",
      "\n",
      "Best: acc=1.000000 | f1=1.000000 | prec=1.000000 | rec=1.000000 | lr=0.0001 | epochs=10 | units=256 | batch_size=128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tolas/Documents/coding/Tetris-EEG/venv/lib/python3.10/site-packages/sklearn/metrics/_classification.py:534: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_acc = 0\n",
    "best_keep = None\n",
    "\n",
    "best_lr = 0\n",
    "best_f1 = 0\n",
    "bar_len = 30\n",
    "\n",
    "status = f\"Best: index= size= | \" f\"acc= | f1= | prec= | rec=\"\n",
    "\n",
    "results = []\n",
    "X_train_sub = X_train.loc[:, features]\n",
    "X_test_sub = X_test.loc[:, features]\n",
    "\n",
    "n_low = (arousal_train == \"low\").sum()\n",
    "n_high = (arousal_train == \"high\").sum()\n",
    "for lr in [0.0001]:\n",
    "    for e in [10]:\n",
    "        for u in [256]:\n",
    "            for b_s in [128]:\n",
    "                lstm, X_test_eval, y_test_eval = train_lstm(\n",
    "                    X_train_sub,\n",
    "                    X_test_sub,\n",
    "                    arousal_train,\n",
    "                    arousal_test,\n",
    "                    lr=lr,\n",
    "                    epochs=e,\n",
    "                    units=u,\n",
    "                    batch_size=b_s,\n",
    "                    bidirectional=False,\n",
    "                )\n",
    "                y_prob = lstm.predict(X_test_eval).ravel()\n",
    "                arousal_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "                acc = accuracy_score(y_test_eval, arousal_pred)\n",
    "                f1 = f1_score(y_test_eval, arousal_pred, average=\"weighted\")\n",
    "                prec = precision_score(y_test_eval, arousal_pred, average=\"weighted\")\n",
    "                rec = recall_score(y_test_eval, arousal_pred, average=\"weighted\")\n",
    "\n",
    "                if acc > best_acc:\n",
    "                    best_acc = acc\n",
    "                    best_model = lstm\n",
    "                    best_lr = lr\n",
    "                    best_e = e\n",
    "                    best_u = u\n",
    "                    best_b_s = b_s\n",
    "                    best_f1 = f1\n",
    "                    best_arousal_pred = arousal_pred\n",
    "                    status = (\n",
    "                        f\"Best: \"\n",
    "                        f\"acc={acc:.6f} | f1={f1:.6f} | prec={prec:.6f} | rec={rec:.6f} | lr={best_lr} | epochs={best_e} | units={best_u} | batch_size={best_b_s}\"\n",
    "                    )\n",
    "                    print(status)\n",
    "\n",
    "print(\"\\nConfusion Matrix (pooled):\")\n",
    "print(confusion_matrix(y_test_eval, best_arousal_pred))\n",
    "\n",
    "print(\"\\nClassification Report (pooled):\")\n",
    "print(classification_report(y_test_eval, best_arousal_pred, zero_division=0))\n",
    "\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2048c3bf",
   "metadata": {},
   "source": [
    "## Choose participants for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b71dbfd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 12 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x1684524d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 13 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x16a2a7a30> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.6666666666666666 0.6666666666666666\n",
      "0.6669501133786847 0.6672335600907029\n",
      "0.6670445956160241 0.6672335600907029\n",
      "0.6669501133786847 0.6666666666666666\n",
      "0.6668934240362812 0.6666666666666666\n",
      "0.6668556311413454 0.6666666666666666\n",
      "0.6668286362163913 0.6666666666666666\n",
      "0.6668083900226757 0.6666666666666666\n",
      "0.6667611489040061 0.6663832199546486\n",
      "0.6667517006802721 0.6666666666666666\n",
      "0.6666650561739847 0.6657986111111112\n",
      "0.6666651903817082 0.6666666666666666\n",
      "0.6666435003488574 0.6663832199546486\n",
      "0.6666451550858439 0.6666666666666666\n",
      "0.666646589191232 0.6666666666666666\n",
      "0.6666098962495973 0.6660595021250759\n",
      "0.6666132356858955 0.6666666666666666\n",
      "0.6666162040737161 0.6666666666666666\n",
      "0.6666188599996609 0.6666666666666666\n",
      "0.6665923151478259 0.666087962962963\n",
      "0.6665958556963422 0.6666666666666666\n",
      "0.6665990743768114 0.6666666666666666\n",
      "0.6666020131720226 0.6666666666666666\n",
      "lr=0.0001, epochs=10, units=128, batch_size=128 -> mean CV acc=0.6666, pooled overall acc=0.6716\n",
      "Pooled confusion matrix for this setting (rows=true, cols=pred):\n",
      "[[    2 13913]\n",
      " [    6 28468]]\n",
      "\n",
      "Best hyperparameters (cross-subject CV):\n",
      "  lr=0.0001\n",
      "  epochs=10\n",
      "  units=128\n",
      "  batch_size=128\n",
      "  mean CV accuracy (unweighted over folds) = 0.6666\n",
      "\n",
      "Pooled metrics for best hyperparameters:\n",
      "  Confusion matrix (rows=true, cols=pred):\n",
      "[[    2 13913]\n",
      " [    6 28468]]\n",
      "  Overall pooled accuracy = 0.6716\n"
     ]
    }
   ],
   "source": [
    "# define the subjects you want to use as \"folds\"\n",
    "subjects = [i for i in range(0, 23)]\n",
    "videos = [j for j in range(0, 18)]\n",
    "\n",
    "\n",
    "# hyper params\n",
    "lr_grid = [0.0001]\n",
    "epochs_grid = [10]\n",
    "units_grid = [128]\n",
    "batch_size_grid = [128]\n",
    "\n",
    "best_lr = None\n",
    "best_e = None\n",
    "best_u = None\n",
    "best_b_s = None\n",
    "best_cv_acc = -np.inf\n",
    "total_size = 0\n",
    "\n",
    "for lr in lr_grid:\n",
    "    for e in epochs_grid:\n",
    "        for u in units_grid:\n",
    "            for b_s in batch_size_grid:\n",
    "                y_true_all = []\n",
    "                y_pred_all = []\n",
    "                acc_list = []\n",
    "\n",
    "                for i in subjects:\n",
    "                    for j in videos:\n",
    "                        while True:\n",
    "                            X_train, X_test, arousal_train, arousal_test = (\n",
    "                                single_user_split(\n",
    "                                    target=\"arousal\",\n",
    "                                    k_holdouts=1,\n",
    "                                    selected_user=i,\n",
    "                                    holdout_videos=[j],\n",
    "                                )\n",
    "                            )\n",
    "                            features = utils.filter_features(\n",
    "                                X_train.columns, remove_bands=[\"gamma\", \"delta\"]\n",
    "                            )\n",
    "                            X_train = X_train.loc[:, features]\n",
    "                            X_test = X_test.loc[:, features]\n",
    "                            arousal_train = pd.Series(\n",
    "                                np.where(arousal_train > 3.8, \"high\", \"low\"),\n",
    "                                index=arousal_train.index,\n",
    "                                dtype=\"string\",\n",
    "                            )\n",
    "                            arousal_test = pd.Series(\n",
    "                                np.where(arousal_test > 3.8, \"high\", \"low\"),\n",
    "                                index=arousal_test.index,\n",
    "                                dtype=\"string\",\n",
    "                            )\n",
    "\n",
    "                            # if you want to enforce balance conditions, re-enable these:\n",
    "                            # c = arousal_test.value_counts()\n",
    "                            # if c.get(\"high\", 0) == 0 or c.get(\"low\", 0) == 0:\n",
    "                            #     continue\n",
    "                            # if c.get(\"low\", 0) * 5 >= arousal_train.value_counts().get(\"low\", 0):\n",
    "                            #     continue\n",
    "\n",
    "                            # if you want balancing:\n",
    "                            # X_train, arousal_train = balance(X_train, arousal_train)\n",
    "                            # X_test, arousal_test = balance(X_test, arousal_test)\n",
    "\n",
    "                            break\n",
    "\n",
    "                        lstm, X_test_eval, y_test_eval = train_lstm(\n",
    "                            X_train,\n",
    "                            X_test,\n",
    "                            arousal_train,\n",
    "                            arousal_test,\n",
    "                            lr=lr,\n",
    "                            epochs=e,\n",
    "                            units=u,\n",
    "                            batch_size=b_s,\n",
    "                            bidirectional=False,\n",
    "                        )\n",
    "\n",
    "                        y_prob = lstm.predict(X_test_eval, verbose=0).ravel()\n",
    "                        arousal_pred = (y_prob >= 0.5).astype(int)\n",
    "\n",
    "                        acc = accuracy_score(y_test_eval, arousal_pred)\n",
    "                        acc_list.append(float(acc))\n",
    "\n",
    "                        y_true_all.extend(y_test_eval.tolist())\n",
    "                        y_pred_all.extend(arousal_pred.tolist())\n",
    "\n",
    "                    print(\n",
    "                        np.mean(acc_list),\n",
    "                        np.mean(acc_list[len(acc_list) - 18 : len(acc_list)]),\n",
    "                    )\n",
    "\n",
    "                mean_acc = float(np.mean(acc_list))\n",
    "                cm = confusion_matrix(y_true_all, y_pred_all, labels=[0, 1])\n",
    "                overall_acc = accuracy_score(y_true_all, y_pred_all)\n",
    "\n",
    "                print(\n",
    "                    f\"lr={lr}, epochs={e}, units={u}, batch_size={b_s} \"\n",
    "                    f\"-> mean CV acc={mean_acc:.4f}, pooled overall acc={overall_acc:.4f}\"\n",
    "                )\n",
    "                print(\n",
    "                    \"Pooled confusion matrix for this setting (rows=true, cols=pred):\"\n",
    "                )\n",
    "                print(cm)\n",
    "\n",
    "                # update best based on mean CV accuracy (your current selection criterion)\n",
    "                if mean_acc > best_cv_acc:\n",
    "                    best_cv_acc = mean_acc\n",
    "                    best_lr = lr\n",
    "                    best_e = e\n",
    "                    best_u = u\n",
    "                    best_b_s = b_s\n",
    "                    best_cm = cm\n",
    "                    best_overall_acc = overall_acc\n",
    "\n",
    "print(\"\\nBest hyperparameters (cross-subject CV):\")\n",
    "print(f\"  lr={best_lr}\")\n",
    "print(f\"  epochs={best_e}\")\n",
    "print(f\"  units={best_u}\")\n",
    "print(f\"  batch_size={best_b_s}\")\n",
    "print(f\"  mean CV accuracy (unweighted over folds) = {best_cv_acc:.4f}\")\n",
    "\n",
    "print(\"\\nPooled metrics for best hyperparameters:\")\n",
    "print(\"  Confusion matrix (rows=true, cols=pred):\")\n",
    "print(best_cm)\n",
    "print(f\"  Overall pooled accuracy = {best_overall_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aff67cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
